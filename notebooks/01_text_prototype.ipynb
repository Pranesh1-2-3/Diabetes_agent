{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a9b3fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\prane\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\prane\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\prane\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: xgboost in c:\\users\\prane\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.0.4)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\prane\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.11.0.post1)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\prane\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (5.0.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\prane\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.53.3)\n",
      "Requirement already satisfied: torch in c:\\users\\prane\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\prane\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\prane\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\prane\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\prane\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\prane\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\prane\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\prane\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\prane\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\prane\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (0.33.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\prane\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\prane\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (4.13.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\prane\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\prane\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\prane\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\prane\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\prane\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\prane\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\prane\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\prane\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\prane\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\prane\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\prane\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\prane\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\prane\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\prane\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\prane\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\prane\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\prane\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\prane\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2023.5.7)\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install pandas numpy scikit-learn xgboost faiss-cpu sentence-transformers transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ec8f017-a5aa-4d4a-b0fd-89667cfe0aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prane\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# --- Imports ---\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline\n",
    "import re\n",
    "from typing import Dict, List, Any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419f6202",
   "metadata": {},
   "source": [
    "# 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f3bbfd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 768 rows, 9 columns\n",
      "Train set: 614 samples\n",
      "Test set: 154 samples\n",
      "Positive class ratio - Train: 0.35, Test: 0.35\n"
     ]
    }
   ],
   "source": [
    "def load_and_split_data(data_path: str) -> tuple:\n",
    "    \"\"\"Load Pima dataset and split into train/test\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(data_path)\n",
    "        print(f\"Dataset loaded: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "        \n",
    "        X = df.drop(\"Outcome\", axis=1)\n",
    "        y = df[\"Outcome\"]\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        print(f\"Train set: {X_train.shape[0]} samples\")\n",
    "        print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "        print(f\"Positive class ratio - Train: {y_train.mean():.2f}, Test: {y_test.mean():.2f}\")\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        raise\n",
    "\n",
    "# Load data\n",
    "data_path = \"../data/raw/diabetes.csv\"\n",
    "X_train, X_test, y_train, y_test = load_and_split_data(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc402a17",
   "metadata": {},
   "source": [
    "# 2. Train and Evaluate Baseline Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "591b644d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training Logistic Regression ===\n",
      "Logistic Regression Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79       100\n",
      "           1       0.61      0.52      0.56        54\n",
      "\n",
      "    accuracy                           0.71       154\n",
      "   macro avg       0.68      0.67      0.67       154\n",
      "weighted avg       0.71      0.71      0.71       154\n",
      "\n",
      "\n",
      "=== Training XGBoost ===\n",
      "XGBoost Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80       100\n",
      "           1       0.62      0.61      0.62        54\n",
      "\n",
      "    accuracy                           0.73       154\n",
      "   macro avg       0.71      0.71      0.71       154\n",
      "weighted avg       0.73      0.73      0.73       154\n",
      "\n",
      "\n",
      "Models saved to ../models/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prane\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:23:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "def train_classifiers(X_train, y_train, X_test, y_test) -> tuple:\n",
    "    \"\"\"Train and evaluate baseline classifiers\"\"\"\n",
    "    \n",
    "    # Logistic Regression\n",
    "    print(\"\\n=== Training Logistic Regression ===\")\n",
    "    logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    logreg.fit(X_train, y_train)\n",
    "    \n",
    "    logreg_pred = logreg.predict(X_test)\n",
    "    print(\"Logistic Regression Report:\")\n",
    "    print(classification_report(y_test, logreg_pred))\n",
    "    \n",
    "    # XGBoost\n",
    "    print(\"\\n=== Training XGBoost ===\")\n",
    "    xgb = XGBClassifier(\n",
    "        use_label_encoder=False, \n",
    "        eval_metric=\"logloss\",\n",
    "        random_state=42,\n",
    "        n_estimators=100\n",
    "    )\n",
    "    xgb.fit(X_train, y_train)\n",
    "    \n",
    "    xgb_pred = xgb.predict(X_test)\n",
    "    print(\"XGBoost Report:\")\n",
    "    print(classification_report(y_test, xgb_pred))\n",
    "    \n",
    "    # Save models\n",
    "    os.makedirs(\"../models\", exist_ok=True)\n",
    "    joblib.dump(logreg, \"../models/logreg.pkl\")\n",
    "    joblib.dump(xgb, \"../models/xgb.pkl\")\n",
    "    print(\"\\nModels saved to ../models/\")\n",
    "    \n",
    "    return logreg, xgb\n",
    "\n",
    "# Train models\n",
    "logreg, xgb = train_classifiers(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d580c3",
   "metadata": {},
   "source": [
    "# 3. FAISS Index and RAG Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ee1f1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model...\n",
      "Creating document embeddings...\n",
      "FAISS index built with 2 documents\n"
     ]
    }
   ],
   "source": [
    "def build_knowledge_base() -> tuple:\n",
    "    \"\"\"Build enhanced knowledge base with diabetes guidelines\"\"\"\n",
    "    \n",
    "    # Document collection with metadata\n",
    "    knowledge_docs = [\n",
    "        {\n",
    "            \"title\": \"WHO Diabetes Definition\",\n",
    "            \"content\": \"Diabetes is a chronic disease characterized by elevated blood glucose levels...\",\n",
    "            \"source\": \"WHO Guidelines\"\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"Risk Factors\",\n",
    "            \"content\": \"Key diabetes risk factors include BMI, glucose intolerance, family history...\",\n",
    "            \"source\": \"Clinical Guidelines\"\n",
    "        },\n",
    "        # Add more documents as needed\n",
    "    ]\n",
    "    \n",
    "    # Extract content and metadata\n",
    "    docs_content = [doc[\"content\"] for doc in knowledge_docs]\n",
    "    docs_metadata = [{k: v for k, v in doc.items() if k != \"content\"} \n",
    "                    for doc in knowledge_docs]\n",
    "    \n",
    "    # Initialize embedding model\n",
    "    print(\"Loading embedding model...\")\n",
    "    embedder = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "    \n",
    "    # Create embeddings\n",
    "    print(\"Creating document embeddings...\")\n",
    "    doc_embeddings = embedder.encode(docs_content, convert_to_numpy=True)\n",
    "    \n",
    "    # Build FAISS index\n",
    "    dim = doc_embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(dim)\n",
    "    index.add(doc_embeddings)\n",
    "    \n",
    "    print(f\"FAISS index built with {len(docs_content)} documents\")\n",
    "    \n",
    "    return embedder, index, docs_content, docs_metadata\n",
    "\n",
    "# Build knowledge base\n",
    "embedder, index, docs_content, docs_metadata = build_knowledge_base()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1189f3",
   "metadata": {},
   "source": [
    "# 4. Pipeline Integration and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af004f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(query: str, patient_features: List[float]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Process a query about diabetes risk and return structured JSON response\n",
    "    \n",
    "    Args:\n",
    "        query: User's question about diabetes risk\n",
    "        patient_features: List of patient measurements\n",
    "        \n",
    "    Returns:\n",
    "        JSON response with prediction, retrieved documents, and explanation\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get classifier prediction\n",
    "        input_data = np.array(patient_features).reshape(1, -1)\n",
    "        probability = float(xgb.predict_proba(input_data)[0, 1])\n",
    "        prediction = int(probability > 0.5)\n",
    "        risk_level = \"High Risk\" if probability >= 0.7 else \"Moderate Risk\" if probability >= 0.4 else \"Low Risk\"\n",
    "        \n",
    "        # Retrieve relevant documents\n",
    "        query_vec = embedder.encode([query], convert_to_numpy=True)\n",
    "        distances, indices = index.search(query_vec, k=3)\n",
    "        \n",
    "        retrieved_docs = []\n",
    "        for i, (idx, dist) in enumerate(zip(indices[0], distances[0])):\n",
    "            doc = {\n",
    "                \"title\": docs_metadata[idx][\"title\"],\n",
    "                \"content\": docs_content[idx],\n",
    "                \"source\": docs_metadata[idx][\"source\"],\n",
    "                \"relevance_score\": float(1 / (1 + dist))\n",
    "            }\n",
    "            retrieved_docs.append(doc)\n",
    "        \n",
    "        # Generate explanation\n",
    "        explanation = {\n",
    "            \"conclusion\": f\"Patient shows {risk_level.lower()} for diabetes\",\n",
    "            \"reasoning\": \"Based on the model prediction and retrieved medical guidelines...\",\n",
    "            \"sources\": [doc[\"source\"] for doc in retrieved_docs]\n",
    "        }\n",
    "        \n",
    "        # Compile response\n",
    "        response = {\n",
    "            \"query\": query,\n",
    "            \"prediction\": {\n",
    "                \"probability\": probability,\n",
    "                \"risk_level\": risk_level,\n",
    "                \"binary_outcome\": prediction\n",
    "            },\n",
    "            \"retrieved_documents\": retrieved_docs,\n",
    "            \"explanation\": explanation\n",
    "        }\n",
    "        \n",
    "        return response\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"error\": str(e),\n",
    "            \"query\": query\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9480507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"query\": \"What is my diabetes risk given my measurements?\",\n",
      "  \"prediction\": {\n",
      "    \"probability\": 9.77476520347409e-05,\n",
      "    \"risk_level\": \"Low Risk\",\n",
      "    \"binary_outcome\": 0\n",
      "  },\n",
      "  \"retrieved_documents\": [\n",
      "    {\n",
      "      \"title\": \"Risk Factors\",\n",
      "      \"content\": \"Key diabetes risk factors include BMI, glucose intolerance, family history...\",\n",
      "      \"source\": \"Clinical Guidelines\",\n",
      "      \"relevance_score\": 0.5293553471565247\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"WHO Diabetes Definition\",\n",
      "      \"content\": \"Diabetes is a chronic disease characterized by elevated blood glucose levels...\",\n",
      "      \"source\": \"WHO Guidelines\",\n",
      "      \"relevance_score\": 0.4831613004207611\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Risk Factors\",\n",
      "      \"content\": \"Key diabetes risk factors include BMI, glucose intolerance, family history...\",\n",
      "      \"source\": \"Clinical Guidelines\",\n",
      "      \"relevance_score\": 2.938735877055719e-39\n",
      "    }\n",
      "  ],\n",
      "  \"explanation\": {\n",
      "    \"conclusion\": \"Patient shows low risk for diabetes\",\n",
      "    \"reasoning\": \"Based on the model prediction and retrieved medical guidelines...\",\n",
      "    \"sources\": [\n",
      "      \"Clinical Guidelines\",\n",
      "      \"WHO Guidelines\",\n",
      "      \"Clinical Guidelines\"\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Test the pipeline\n",
    "test_query = \"What is my diabetes risk given my measurements?\"\n",
    "#test_patient = [6, 180, 90, 35, 100, 33.0, 0.9, 55]\n",
    "test_patient=[1, 85, 66, 20, 0, 22.0, 0.1, 25]\n",
    "# Process query\n",
    "result = process_query(test_query, test_patient)\n",
    "\n",
    "# Pretty print the JSON response\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85aadfab-5885-4101-b03c-fba26855779c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
